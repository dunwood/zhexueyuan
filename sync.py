import requests
from bs4 import BeautifulSoup
import os
import re
import subprocess
from datetime import datetime
import time
import json
import sys

# --- è§„èŒƒåŒ–è·¯å¾„é…ç½® ---
BASE_DIR = "articles"
IMAGE_SUBDIR = "images"
INDEX_FILE = "index.html"
LINKS_FILE = "links.txt"
LOG_FILE = "sync.log"

# --- æ–‡ç« åˆ†ç±»æ˜ å°„ ---
CAT_MAP = {
    "1": "laochan-column",
    "2": "ancient-greek",
    "3": "metaphysics",
    "4": "ethics",
    "5": "epistemology",
    "6": "logic",
    "7": "aesthetics",
    "8": "math-science-philosophy"
}

CAT_NAMES = {
    "laochan-column": "è€è‰ä¸“æ ",
    "ancient-greek": "å¤å¸Œè…Šå“²å­¦",
    "metaphysics": "å½¢è€Œä¸Šå­¦",
    "ethics": "ä¼¦ç†å­¦",
    "epistemology": "è®¤è¯†è®º",
    "logic": "é€»è¾‘å­¦",
    "aesthetics": "ç¾å­¦",
    "math-science-philosophy": "æ•°ç†ã€ç§‘å“²"
}

def log(message):
    """è®°å½•æ—¥å¿—åˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_message = f"[{timestamp}] {message}"
    print(log_message)
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(log_message + '\n')

def is_git_repo():
    """æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æ˜¯gitä»“åº“"""
    return os.path.exists('.git')

def git_push():
    """è‡ªåŠ¨æ¨é€åˆ°GitHub"""
    if not is_git_repo():
        log("âš ï¸ å½“å‰ç›®å½•ä¸æ˜¯Gitä»“åº“ï¼Œè·³è¿‡æ¨é€")
        return False
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
        result = subprocess.run(['git', 'status', '--porcelain'], 
                              capture_output=True, text=True, check=True)
        if not result.stdout.strip():
            log("ğŸ“‹ æ²¡æœ‰æ–°çš„å˜æ›´éœ€è¦æäº¤")
            return True
        
        # æ·»åŠ æ‰€æœ‰å˜æ›´
        log("ğŸ“¦ æ­£åœ¨æ·»åŠ æ–‡ä»¶åˆ°Git...")
        subprocess.run(['git', 'add', '.'], check=True)
        
        # æäº¤
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        commit_msg = f"è‡ªåŠ¨åŒæ­¥æ–‡ç«  - {timestamp}"
        log(f"ğŸ’¾ æ­£åœ¨æäº¤: {commit_msg}")
        subprocess.run(['git', 'commit', '-m', commit_msg], check=True)
        
        # æ¨é€
        log("ğŸš€ æ­£åœ¨æ¨é€åˆ°GitHub...")
        subprocess.run(['git', 'push'], check=True)
        
        log("âœ… GitHubæ¨é€æˆåŠŸï¼")
        return True
        
    except subprocess.CalledProcessError as e:
        log(f"âŒ Gitæ“ä½œå¤±è´¥: {e}")
        return False
    except Exception as e:
        log(f"âŒ æ¨é€å‡ºé”™: {e}")
        return False

def download_article(url, category_id="laochan-column"):
    """ä¸‹è½½å•ä¸ªæ–‡ç« """
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    try:
        log(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
        res = requests.get(url, headers=headers, timeout=30)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')

        # 1. æ ‡é¢˜å¤„ç†
        title_tag = soup.find('h1', class_='rich_media_title')
        title = title_tag.get_text().strip() if title_tag else "æœªå‘½å"
        safe_title = re.sub(r'[\\/:*?"<>|]', '', title)
        date_str = datetime.now().strftime('%Y-%m-%d')
        
        # å›¾ç‰‡ä¸“å±æ–‡ä»¶å¤¹
        img_folder_name = safe_title
        local_img_dir = os.path.join(BASE_DIR, IMAGE_SUBDIR, img_folder_name)
        os.makedirs(local_img_dir, exist_ok=True)

        # 2. å®šä½æ­£æ–‡
        main_area = soup.find('div', id='js_content')
        if not main_area:
            log(f"âŒ æ— æ³•æŠ“å–æ­£æ–‡: {title}")
            return False

        md_content = f"# {title}\n\n---\n\n"
        img_count = 0
        
        # 3. é€’å½’éå†æ‰€æœ‰å…ƒç´ 
        for element in main_area.children:
            if isinstance(element, str):
                if element.strip():
                    md_content += f"{element.strip()}\n\n"
                continue

            # A. å¤„ç†å›¾ç‰‡
            if element.find_all('img') or element.name == 'img':
                imgs = element.find_all('img') if element.name != 'img' else [element]
                for img in imgs:
                    src = img.get('data-src') or img.get('src')
                    if src and 'wx_fmt=gif' not in src:
                        try:
                            img_res = requests.get(src, headers={'Referer': 'https://mp.weixin.qq.com/'}, timeout=10)
                            if len(img_res.content) > 5000:
                                img_count += 1
                                img_name = f"{img_count}.jpg"
                                with open(os.path.join(local_img_dir, img_name), 'wb') as f:
                                    f.write(img_res.content)
                                md_img_path = f"articles/images/{img_folder_name}/{img_name}"
                                md_content += f"![å›¾ç‰‡]({md_img_path})\n\n"
                        except Exception as e:
                            log(f"âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")
                            continue
            
            # B. å¤„ç†è§†é¢‘
            html_str = str(element)
            if 'finder_video_card' in html_str or element.find('iframe') or 'video' in html_str:
                video_note = "ã€ğŸ“¹ æ­¤å¤„åŸæ–‡ç« æœ‰ä¸€æ¡è§†é¢‘ï¼Œå› ç‰ˆæƒé™åˆ¶æ— æ³•åŒæ­¥ï¼Œè¯·ç‚¹å‡»æ–‡æœ«'é˜…è¯»åŸæ–‡'æŸ¥çœ‹ã€‘"
                if video_note not in md_content:
                    md_content += f"\n> {video_note}\n\n"

            # C. å¤„ç†æ–‡æœ¬
            text = element.get_text(strip=True)
            if text and not element.find('img'):
                md_content += f"{text}\n\n"

        # 4. ä¿å­˜ MD
        md_file_dir = os.path.join(BASE_DIR, category_id)
        os.makedirs(md_file_dir, exist_ok=True)
        md_file_name = f"{safe_title}.md"
        md_file_path = os.path.join(md_file_dir, md_file_name)
        
        with open(md_file_path, 'w', encoding='utf-8') as f:
            f.write(md_content)

        # 5. åŒæ­¥ index.html
        with open(INDEX_FILE, 'r', encoding='utf-8') as f:
            index_content = f.read()

        if f"'{title}'" in index_content or f'"{title}"' in index_content:
            log(f"âš ï¸ é¦–é¡µå·²å­˜åœ¨ã€Š{title}ã€‹ï¼Œä»…æ›´æ–°æœ¬åœ°æ–‡ä»¶ã€‚")
        else:
            md_path_for_index = f"articles/{category_id}/{md_file_name}"
            article_id = f"art_{datetime.now().strftime('%H%M%S')}"
            new_entry = f"{{ id: '{article_id}', title: '{title}', filePath: '{md_path_for_index}', date: '{date_str}' }},"
            pattern = rf"(['\"]{category_id}['\"]:\s*\[)"
            index_content = re.sub(pattern, f"\\1\n                {new_entry}", index_content)
            with open(INDEX_FILE, 'w', encoding='utf-8') as f:
                f.write(index_content)
            log(f"âœ… é¦–é¡µ index.html å·²æ›´æ–°")

        log(f"âœ… æ–‡ç« ã€Š{title}ã€‹å¤„ç†å®Œæˆï¼Œå…±{img_count}å¼ å›¾ç‰‡")
        return True

    except Exception as e:
        log(f"âŒ å¤„ç†æ–‡ç« å¤±è´¥ ({url}): {e}")
        return False

def batch_sync(links_file=LINKS_FILE):
    """æ‰¹é‡åŒæ­¥æ–‡ç« """
    log("\n" + "="*50)
    log("=== å“²å­¦å›­å…¨è‡ªåŠ¨æ‰¹é‡åŒæ­¥ç³»ç»Ÿ ===")
    log("="*50)
    
    if not os.path.exists(links_file):
        log(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°é“¾æ¥æ–‡ä»¶ {links_file}")
        log(f"è¯·åˆ›å»º {links_file} æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªé“¾æ¥ï¼Œæ ¼å¼ï¼š")
        log("  é“¾æ¥ [åˆ†ç±»ç¼–å·]")
        log("ä¾‹å¦‚ï¼š")
        log("  https://mp.weixin.qq.com/s/xxxxx 1")
        log("  https://mp.weixin.qq.com/s/yyyyy 1")
        log("")
        log("åˆ†ç±»ç¼–å·ï¼š1=è€è‰ä¸“æ , 2=å¤å¸Œè…Š, 3=å½¢è€Œä¸Šå­¦, 4=ä¼¦ç†å­¦")
        log("         5=è®¤è¯†è®º, 6=é€»è¾‘å­¦, 7=ç¾å­¦, 8=æ•°ç†ç§‘å“²")
        return
    
    # è¯»å–é“¾æ¥
    with open(links_file, 'r', encoding='utf-8') as f:
        lines = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    if not lines:
        log("âš ï¸ é“¾æ¥æ–‡ä»¶ä¸ºç©º")
        return
    
    log(f"ğŸ“‹ å…±æ‰¾åˆ° {len(lines)} ä¸ªå¾…å¤„ç†é“¾æ¥")
    
    success_count = 0
    fail_count = 0
    
    for i, line in enumerate(lines, 1):
        log(f"\n[{i}/{len(lines)}] å¤„ç†ä¸­...")
        
        # è§£æé“¾æ¥å’Œåˆ†ç±»
        parts = line.split()
        url = parts[0]
        category_id = parts[1] if len(parts) > 1 else "1"
        
        # ä¸‹è½½æ–‡ç« 
        if download_article(url, category_id):
            success_count += 1
        else:
            fail_count += 1
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        if i < len(lines):
            time.sleep(2)
    
    log(f"\n{'='*50}")
    log(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼šæˆåŠŸ {success_count} ç¯‡ï¼Œå¤±è´¥ {fail_count} ç¯‡")
    log(f"{'='*50}\n")
    
    # è‡ªåŠ¨æ¨é€åˆ°GitHub
    if success_count > 0:
        log("ğŸ”„ å¼€å§‹æ¨é€åˆ°GitHub...")
        git_push()
    
    return success_count, fail_count

def interactive_mode():
    """äº¤äº’å¼å•ç¯‡æ¨¡å¼ï¼ˆä¿ç•™åŸåŠŸèƒ½ï¼‰"""
    print("=== å“²å­¦å›­ä¸€é”®åŒæ­¥ (äº¤äº’æ¨¡å¼) ===")
    
    if not os.path.exists(INDEX_FILE):
        print(f"âŒ é”™è¯¯ï¼šåœ¨è„šæœ¬æ—è¾¹æ²¡æ‰¾åˆ° {INDEX_FILE}")
        return

    url = input("è¯·è¾“å…¥å¾®ä¿¡æ–‡ç« é“¾æ¥: ").strip()
    if not url:
        return
    
    print("\nè¯·é€‰æ‹©æ–‡ç« åˆ†ç±»:")
    for key, value in CAT_NAMES.items():
        num = [k for k, v in CAT_MAP.items() if v == key][0]
        print(f"  [{num}] {value}")
    
    category_id = CAT_MAP.get(input("è¯·è¾“å…¥ç¼–å· (é»˜è®¤'1'): ").strip(), "laochan-column")
    
    if download_article(url, category_id):
        git_push()
    
    input("\næŒ‰å›è½¦é€€å‡º...")

if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "--batch" or sys.argv[1] == "-b":
            # æ‰¹é‡æ¨¡å¼
            links_file = sys.argv[2] if len(sys.argv) > 2 else LINKS_FILE
            batch_sync(links_file)
        elif sys.argv[1] == "--help" or sys.argv[1] == "-h":
            print("å“²å­¦å›­æ–‡ç« åŒæ­¥å·¥å…·")
            print("")
            print("ç”¨æ³•:")
            print("  python sync.py              - äº¤äº’å¼å•ç¯‡æ¨¡å¼")
            print("  python sync.py --batch      - æ‰¹é‡æ¨¡å¼ï¼ˆè¯»å–links.txtï¼‰")
            print("  python sync.py --batch file - æ‰¹é‡æ¨¡å¼ï¼ˆè¯»å–æŒ‡å®šæ–‡ä»¶ï¼‰")
            print("")
            print("links.txt æ ¼å¼:")
            print("  # è¿™æ˜¯æ³¨é‡Š")
            print("  https://mp.weixin.qq.com/s/xxxxx 1")
            print("  https://mp.weixin.qq.com/s/yyyyy 2")
            print("")
            print("åˆ†ç±»ç¼–å·ï¼š")
            for num, cat in CAT_MAP.items():
                print(f"  {num} = {CAT_NAMES[cat]}")
        else:
            print(f"æœªçŸ¥å‚æ•°: {sys.argv[1]}")
            print("ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©")
    else:
        # é»˜è®¤äº¤äº’æ¨¡å¼
        interactive_mode()
